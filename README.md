**Project Description**
This project provides an automated testing framework for an API that manages Models and Model Versions, including inference functionality. The tests cover endpoints for creating, deleting, and performing operations on Models and their Versions.

**Prerequisites**
1. Install Python:
Requires Python 3.11. Make sure Python is installed and added to your system's PATH.

2. Set Up a Virtual Environment:
python3.11 -m venv venv          
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`

3. Install Dependencies:
pip install -r requirements.txt

4. Project Utilities
The project includes utility scripts and test data management:

Utilities:

basetest.py: Contains methods to clear previously created Models and Model Versions before test execution, ensuring a clean test environment.
keywordrepository.py: Utility for accessing and updating test data stored in JSON files.
model_utils.py: Functions for creating and deleting models and their versions.

Test Data:

Data is fetched from JSON files and used in the test scripts:

test_inference_data.json: Contains test data for inference-related tests.
test_model_data.json: Contains test data for model-related tests.
test_model_version_data.json: Contains test data for model version-related tests.

5. Test Scripts
All test scripts are located in the tests/ directory and cover various API operations:

test_inference.py: Test cases for inference operations.
test_model.py: Test cases for managing models, such as adding or deleting a model.
test_model_version.py: Test cases for managing model versions, such as adding or deleting versions.

6. Test Execution
Setup Before Running Tests:

Before test execution starts, each test script contains a cleanup function that runs to remove any previously created models and versions. This ensures a clean environment for running tests.

7. Run Tests: pytest --alluredir=allure-results

8. Reporting:- Allure Reports:
To view the test reports using Allure:- allure serve allure-results

9. HTML Report:

HTML report can be generated
pytest --html=report.html --self-contained-html

10. Troubleshooting
Inference Takes Too Long:
If the inference operation takes longer than expected, ensure that the server is running correctly and consider adjusting the timeout settings in the test scripts.

11API Documentation
The following endpoints are covered in the tests:

Model Endpoints:

GET /models: Fetch all models.
POST /models: Create a new model.
DELETE /models/{model_id}: Delete a model by its ID.
Model Version Endpoints:

GET /models/{model_id}/versions: Fetch all versions of a model.
POST /models/{model_id}/versions: Add a new version to a model.
DELETE /models/{model_id}/versions/{version_id}: Delete a specific model version.
Inference Endpoint:

POST /models/{model_id}/versions/{version_id}/infer: Perform inference using a specified model version.
   

**Project Structure**


api-testing/
├── .venv/                              # Directory for the virtual environment setup
├── allure-results/                     # Folder to store results generated by Allure reports
├── tests/                              # Directory containing all test scripts
│   ├── report.html                     # Generated test report in HTML format
│   ├── test_inference.py               # Test cases for inference-related functionalities
│   ├── test_model.py                   # Test cases for operations related to models
│   └── test_model_version.py           # Test cases for operations related to model versions
├── utils/                              # Folder for utility scripts and test data files
│   ├── basetest.py                     # Base setup for tests, including cleanup to remove existing models before tests run
│   ├── keywordrepository.py            # Utility script for accessing and updating test data stored in JSON files
│   ├── model_utils.py                  # Utility functions for creating and deleting models and their versions
│   ├── test_inference_data.json        # JSON file containing test data for inference-related tests
│   ├── test_model_data.json            # JSON file containing test data for model-related tests
│   └── test_model_version_data.json    # JSON file containing test data for model version-related tests
├── venv/                               # Directory for the virtual environment setup (alternatively named .venv)
├── pytest.ini                          # Configuration file for pytest settings
├── README.md                           # Documentation for the project, including setup and usage instructions
├── report.html                         # Generated test execution report in HTML format
└── requirements.txt                    # File listing the project's dependencies


Advantages
1. Modular Structure: The project is set up in a neat, organized way with a clear separation between test scripts, utilities, and data. This makes it easy to manage, extend, and keep everything in its place.

2. Automated Cleanup: Before running new tests, the framework automatically cleans up any previously created models or versions. This helps ensure a fresh testing environment every time.

3. Data-Driven Testing:: By using JSON files for test data, it's easy to manage test cases and cover a variety of scenarios. You can easily update or add new cases without changing the code.

4. Comprehensive Reporting: The Allure reports give you a detailed look at the test execution process, showing logs, results, and history, so you know exactly what's happening and where any issues might be.

5. Reusable Utilities: The utility functions for managing models and performing inference can be used across multiple tests, reducing code duplication and promoting best practices.

Disadvantages
1. Slow Inference Tests: Inference operations can take a long time to complete, which slows down the overall test execution.

2. No Parallel Execution of Tests: Tests run one after another, which is manageable for now since there are only a few tests, but could become a bottleneck if more tests are added in the future.
